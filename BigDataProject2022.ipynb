{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6f64cc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests, json, os\n",
    "import re\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pprint\n",
    "import gensim\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/107.0.0.0 Safari/537.36 Edg/107.0.1418.52\",\n",
    "}\n",
    "\n",
    "params = {\n",
    "    \"q\": \"\",\n",
    "    \"hl\": \"en\",\n",
    "    \"start\": 0\n",
    "}\n",
    "from tkinter import *\n",
    "window=Tk()\n",
    "\n",
    "\n",
    "link = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ff744b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPARK RELATED CODE\n",
    "import findspark\n",
    "\n",
    "findspark.init()\n",
    "\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "conf = SparkConf()\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName('Sparkler') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.conf.set('spark.sql.caseSensitive', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9403c614",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gensimImplementation(documents):\n",
    "    q = params['q']\n",
    "    for document in documents:\n",
    "        print(gensim.utils.simple_preprocess(document))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c5feb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Similar Articles\n",
    "def getSimilarArticles(df, vectorizer):    \n",
    "    q = [params['q']]\n",
    "    q_vector = vectorizer.transform(q).toarray().reshape(df.shape[0],)\n",
    "    print(q_vector)\n",
    "    sim = {}\n",
    "    \n",
    "    for i in range(df.shape[1]):\n",
    "        sim[i] = np.dot(df.loc[:, i].values, q_vector) / np.linalg.norm(df.loc[:,i]) * np.linalg.norm(q_vector)\n",
    "        \n",
    "    sim_sorted = sorted(sim.items(), key = lambda x:x[1], reverse = True)\n",
    "    print(sim_sorted)\n",
    "    for k,v in sim_sorted[:5]:\n",
    "        if v != 0.0:\n",
    "            print(\"Similarities: {}\".format(v))\n",
    "            print('Link to the article:', link[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df8673d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorizerMethod(documents_clean):\n",
    "    # Instantiate a TfIdfVectorizer Object and transform the data to vectors\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X = vectorizer.fit_transform(documents_clean)\n",
    "    X = X.T.toarray()\n",
    "\n",
    "    df = pd.DataFrame(X, index=vectorizer.get_feature_names_out())\n",
    "    getSimilarArticles(df, vectorizer)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db9a0d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanData(documents):\n",
    "    documents_clean = []\n",
    "    for d in documents:\n",
    "        # Remove Unicode\n",
    "        document_test = re.sub(r'[^\\x00-\\x7F]+', ' ', d)\n",
    "        # Remove Mentions\n",
    "        document_test = re.sub(r'@\\w+', '', document_test)\n",
    "        # Lowercase the document\n",
    "        document_test = document_test.lower()\n",
    "        # Remove punctuations\n",
    "        document_test = re.sub(r'[%s]' % re.escape(string.punctuation), ' ', document_test)\n",
    "        # Lowercase the numbers\n",
    "        document_test = re.sub(r'[0-9]', '', document_test)\n",
    "        # Remove the doubled space\n",
    "        document_test = re.sub(r'\\s{2,}', ' ', document_test)\n",
    "        documents_clean.append(document_test)\n",
    "    vectorizerMethod(documents_clean)\n",
    "#     gensimImplementation(documents=documents_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89c6c41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collectDocumentFromLinks(link):\n",
    "    #Retrieve paragrahs from each link, combine each paragrah as a string and save it to docs\n",
    "    documents = []\n",
    "    print('Fetching data from each link...')\n",
    "    for i in link:\n",
    "        r = requests.get(i, headers=headers)\n",
    "        soup = BeautifulSoup(r.content,'html.parser')\n",
    "\n",
    "        sen = []\n",
    "        # for springer abstracts\n",
    "        if soup.find('div', {'id':'Abs1-content'}):\n",
    "            for i in soup.find('div', {'id':'Abs1-content'}).find_all('p'):\n",
    "                sen.append(i.text)\n",
    "\n",
    "        documents.append(' '.join(sen))\n",
    "    print('Fetched data from each link...')\n",
    "    cleanData(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a99bbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collectSpringerLinks(soup):\n",
    "    #Retrieve all popular new links\n",
    "    print(len(soup))\n",
    "    i=0\n",
    "    for i in range(0, len(soup)):\n",
    "        data = soup[i].find_all(\"div\", {\"class\": \"gs_ri\"})\n",
    "        for j in range(len(data)):    \n",
    "\n",
    "            temp = data[j].find('a')\n",
    "\n",
    "            if 'link.springer.com/article' in temp['href'] and 'books.google.com' not in temp['href']:\n",
    "                link.append(temp['href'])\n",
    "    #             print(temp['href'], j)\n",
    "\n",
    "    print(len(link))\n",
    "    if len(link)>0:\n",
    "        collectDocumentFromLinks(link)\n",
    "    else: \n",
    "        print('No links found. Try with other keywords.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed094191",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collectGoogleScholarPages(query):\n",
    "    params['q'] = query\n",
    "    soup = []\n",
    "    while True:\n",
    "        url = 'https://scholar.google.com/scholar'\n",
    "        req = requests.get(url, headers=headers, params=params)\n",
    "        print(req.url)\n",
    "        tempData = BeautifulSoup(req.content,'html.parser')\n",
    "#         print(tempData)\n",
    "        soup.append(tempData)\n",
    "        if tempData.find('span', {'class': 'gs_ico gs_ico_nav_next'}) and params['start']<=100:\n",
    "            params['start']+=10\n",
    "        else:\n",
    "            break\n",
    "    # call collectSpringerLinks()\n",
    "    collectSpringerLinks(soup)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a37613a9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter keywords on which you want to search documents:brain tumor springer covid-19\n",
      "https://scholar.google.com/scholar?q=brain+tumor+springer+covid-19&hl=en&start=0\n",
      "https://scholar.google.com/scholar?q=brain+tumor+springer+covid-19&hl=en&start=10\n",
      "https://scholar.google.com/scholar?q=brain+tumor+springer+covid-19&hl=en&start=20\n",
      "https://scholar.google.com/scholar?q=brain+tumor+springer+covid-19&hl=en&start=30\n",
      "https://scholar.google.com/scholar?q=brain+tumor+springer+covid-19&hl=en&start=40\n",
      "https://scholar.google.com/scholar?q=brain+tumor+springer+covid-19&hl=en&start=50\n",
      "https://scholar.google.com/scholar?q=brain+tumor+springer+covid-19&hl=en&start=60\n",
      "https://scholar.google.com/scholar?q=brain+tumor+springer+covid-19&hl=en&start=70\n",
      "https://scholar.google.com/scholar?q=brain+tumor+springer+covid-19&hl=en&start=80\n",
      "https://scholar.google.com/scholar?q=brain+tumor+springer+covid-19&hl=en&start=90\n",
      "https://scholar.google.com/scholar?q=brain+tumor+springer+covid-19&hl=en&start=100\n",
      "https://scholar.google.com/scholar?q=brain+tumor+springer+covid-19&hl=en&start=110\n",
      "12\n",
      "111\n",
      "Fetching data from each link...\n",
      "Fetched data from each link...\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[(2, nan), (3, nan), (5, nan), (7, 0.15393686549257302), (11, 0.11460837372063983), (6, 0.1086372320696182), (18, nan), (19, nan), (20, nan), (27, nan), (29, nan), (47, 0.30289434800148596), (25, 0.1600944513417096), (44, 0.11658004809840797), (1, 0.10442854124864993), (4, 0.0954534212421893), (38, 0.08407863884485642), (37, 0.0823269500896831), (35, 0.07900273244156074), (24, 0.07374792237291078), (9, 0.0650110398955221), (39, 0.062247995751014175), (48, 0.05665519155203827), (17, 0.05329625286430244), (51, 0.05240846796356541), (26, 0.05087653888768951), (49, 0.049412083877737406), (50, 0.047892438459234694), (21, 0.047240468134283), (22, 0.0470873303360591), (43, 0.04511958122200457), (41, 0.04292325300856064), (34, 0.04061801238761595), (28, 0.03771129497402881), (31, 0.03613139213063853), (45, 0.03359453352359879), (10, 0.03215592249032495), (8, 0.02897158767913371), (36, 0.02876447090918214), (30, 0.02461755181674244), (46, 0.023752802292588165), (32, 0.023438613024599313), (15, 0.023161890705307983), (42, 0.022511147660468588), (14, 0.022209021778580484), (52, nan), (54, 0.021314721802773304), (23, 0.02093347919963903), (0, 0.01950624794745863), (13, 0.018954840386651274), (33, 0.018040648673202302), (12, 0.01529431019534108), (40, 0.009834065060156279), (53, 0.0034778312321672653), (16, 0.0), (64, nan), (68, nan), (70, 0.1027174371207523), (73, nan), (77, nan), (80, 0.16217766505027767), (63, 0.14499851953565226), (78, 0.0805913021741244), (81, nan), (90, nan), (91, nan), (104, 0.23229813060943738), (102, 0.12278488305186733), (66, 0.08184738722838864), (85, 0.07785185910143036), (69, 0.06367846676188875), (87, 0.056711536797607744), (75, 0.055382957359949365), (101, 0.053490113018415365), (72, 0.04795227801051368), (60, 0.0466745150101505), (65, 0.046455127939888), (106, 0.04503889346640662), (79, 0.042837179100806914), (55, 0.04268274134910389), (89, 0.042294486980224026), (107, 0.041282425624609966), (88, 0.04067943595151153), (86, 0.038090749841896254), (92, 0.03695875139994768), (96, 0.03624121119982645), (71, 0.03486752417096348), (94, 0.03378830080302666), (95, 0.0330618086034872), (93, 0.031095245288159646), (103, 0.03080469615552711), (97, 0.030721884380393017), (83, 0.03020945116675959), (100, 0.029233265002170668), (76, 0.029086465379295615), (67, 0.027487610502224626), (84, 0.025719805057085834), (57, 0.0255910515865298), (74, 0.025452295432887743), (108, 0.022567994285620393), (82, 0.02203234362247232), (98, 0.021174799328665856), (58, 0.020568374840949546), (56, 0.01967805035899454), (105, 0.016689365983452817), (109, 0.01527681565878625), (61, 0.012021990797423865), (62, 0.00943635119033517), (110, 0.006788038506490014), (59, 0.006127310548629595), (99, 0.004815763247851864)]\n",
      "Similarities: nan\n",
      "Link to the article: https://link.springer.com/article/10.1007/s13577-022-00716-2\n",
      "Similarities: nan\n",
      "Link to the article: https://link.springer.com/article/10.1007/s00415-021-10462-4\n",
      "Similarities: nan\n",
      "Link to the article: https://link.springer.com/article/10.1007/s11060-020-03496-7\n",
      "Similarities: 0.15393686549257302\n",
      "Link to the article: https://link.springer.com/article/10.1007/s11060-021-03838-z\n",
      "Similarities: 0.11460837372063983\n",
      "Link to the article: https://link.springer.com/article/10.1007/s12029-020-00528-3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\babap\\AppData\\Local\\Temp\\ipykernel_24100\\3896186481.py:9: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  sim[i] = np.dot(df.loc[:, i].values, q_vector) / np.linalg.norm(df.loc[:,i]) * np.linalg.norm(q_vector)\n"
     ]
    }
   ],
   "source": [
    "# lbl=Label(window, text=\"Enter keywords to search documents\", fg='black', font=(\"Helvetica\", 12))\n",
    "# lbl.place(relx=.5, rely=.25,anchor= CENTER)\n",
    "\n",
    "\n",
    "# txtfld=Entry(window, text=\"Enter keywords (',' separated)\", bd=2)\n",
    "# txtfld.place(relx=.5, rely=.35,anchor= CENTER)\n",
    "\n",
    "# btn=Button(window, text=\"Search Documents\", fg='black', command=lambda: collectGoogleScholarPages(txtfld.get()))\n",
    "# btn.place(relx=.5, rely=.45,anchor= CENTER)\n",
    "\n",
    "# window.title('Sparkler for Documents')\n",
    "# window.geometry(\"500x300+250+250\")\n",
    "# window.mainloop()\n",
    "\n",
    "\n",
    "keywords = input(\"Enter keywords on which you want to search documents:\")\n",
    "collectGoogleScholarPages(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fcbccd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "8c63ac64",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
